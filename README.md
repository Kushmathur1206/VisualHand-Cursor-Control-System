# 🚀👁️‍🗨️Hand-and-eye-controlled-cursor

💡Potential Use Cases
Accessibility Enhancement
- Provides an alternative input method for individuals with mobility impairments, allowing them to interact with computers without traditional peripherals.
- Touchless Interfaces in Healthcare
  Enables medical professionals to navigate digital records or imaging without physical contact, maintaining sterility in environments like operating rooms.
- Interactive Presentations
  Facilitates dynamic presentations where speakers can control slides and pointers through gestures, enhancing engagement without being tethered to a device.
- Public Information Kiosks
  Implements hygienic, touch-free navigation in public kiosks, reducing the spread of germs and improving user experience.

🚀 Features
- Dual-Mode Control: Switch seamlessly between hand gesture control and eye-tracking for cursor movement.
- Real-Time Tracking: Utilizes webcam input to detect and interpret user gestures and eye positions in real-time.
- Gesture Recognition: Implements predefined hand gestures to execute cursor actions like movement, clicks, and scrolling.
- Eye Movement Detection: Tracks eye movements to control cursor direction and position.
- Customizable Interface: Easily adaptable to recognize new gestures or modify existing ones to suit user preferences.

🧰 Technologies Used
- Programming Language: Python
- Libraries:
- OpenCV: For image and video processing.
- Mediapipe: For hand and eye landmark detection.
- PyAutoGUI: For controlling mouse movements and clicks.
- NumPy: For numerical operations.
